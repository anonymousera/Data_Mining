{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Azhterrkymt3"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00325/Sensorless_drive_diagnosis.txt'\n",
        "data = pd.read_csv(url, sep=' ', header=None)\n",
        "\n",
        "# Split data into features and labels\n",
        "X = data.iloc[:,:-1].values\n",
        "y = data.iloc[:,-1].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Keras model\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, input_dim=48, activation='relu'))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(11, activation='softmax'))\n",
        "    optimizer = Adam(lr=0.001)\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Use KerasClassifier to wrap the Keras model for Scikit-learn compatibility\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "# Define the parameter grid for grid search\n",
        "param_grid = {\n",
        "              'batch_size': [32, 64, 128],\n",
        "              'epochs': [10, 20, 50],\n",
        "              'optimizer': ['adam', 'rmsprop']\n",
        "              }\n",
        "\n",
        "# Define the Keras model\n",
        "def create_model(optimizer='adam'):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, input_dim=48, activation='relu'))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(11, activation='softmax'))\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Use KerasClassifier to wrap the Keras model for Scikit-learn compatibility\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "# Define the parameter grid for grid search\n",
        "param_grid = {\n",
        "              'batch_size': [32, 64],\n",
        "              'epochs': [10],\n",
        "             }\n",
        "\n",
        "# Perform grid search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and accuracy score from grid search\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "# Define the parameter distributions for random search\n",
        "param_dist = {'batch_size': [32, 64, 128],\n",
        "              'epochs': [10, 20, 50],\n",
        "              'optimizer': ['adam', 'rmsprop']}\n",
        "\n",
        "# Perform random search\n",
        "random = RandomizedSearchCV(estimator=model, param_distributions=param_dist, cv=3, n_iter=10, random_state=42)\n",
        "random_result = random.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and accuracy score from random search\n",
        "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
        "\n",
        "# Define the k-fold cross validation generator\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Train the model using k-fold cross validation\n",
        "cv_scores = []\n",
        "for train_idx, test_idx in kfold.split(X_train, y_train):\n",
        "    # Fit the model\n",
        "    model = create_model()\n",
        "    model.fit(X_train[train_idx], y_train[train_idx], epochs=20, batch_size=64, verbose=0)\n",
        "    # Evaluate the model on the test fold\n",
        "    scores = model.evaluate(X_train[test_idx], y_train[test_idx], verbose=0)\n",
        "    cv_scores.append(scores[1] * 100)\n",
        "\n",
        "# Print the mean and standard deviation of the k-fold cross validation scores\n",
        "print(\"CV Scores: %.2f%% (+/- %.2f%%)\" % (np.mean(cv_scores), np.std(cv_scores)))\n"
      ]
    }
  ]
}