{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZusuF7L1aJN_",
        "outputId": "9f6c850f-de37-4427-f2a1-a7c1e081f944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters (Grid Search): {'var_smoothing': 0.1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters (Random Search): {'var_smoothing': 0.1}\n",
            "Accuracy: 0.8063015873015873\n",
            "Precision: 0.8194845084672376\n",
            "Recall: 0.8028015655521654\n",
            "F1-score: 0.8048942443963527\n",
            "Confusion matrix:\n",
            " [[5602    8   34    9   10  130  125    1  238   55]\n",
            " [   0 6803   18   22    4   48   40    2  145   11]\n",
            " [  63  243 4796  186   76   20  346   64  479   42]\n",
            " [  45  292  214 4935   30  113   82   63  348  303]\n",
            " [  13   88   33    0 4110   48  134   21  144 1517]\n",
            " [ 181  146   42  632  162 3732  172   33  304  299]\n",
            " [  50  162   94    2   72  133 5587    0   64    3]\n",
            " [  23  267   29   19  140    2    9 5326  133  591]\n",
            " [  48  645   78  221  101  132   55   19 4458  418]\n",
            " [  35  163   12   44  296   18    5  126  116 5448]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X = mnist.data\n",
        "y = mnist.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "n_samples = len(X)\n",
        "train_data = X[:int(n_samples * 0.1)]\n",
        "test_data = X[int(n_samples * 0.1):]\n",
        "train_labels = y[:int(n_samples * 0.1)]\n",
        "test_labels = y[int(n_samples * 0.1):]\n",
        "\n",
        "# Define the Naive Bayes classifier\n",
        "nb = GaussianNB()\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid = {\n",
        "    'var_smoothing': [1e-7, 1e-5, 1e-3, 1e-1]\n",
        "}\n",
        "\n",
        "# Perform a grid search over the parameter grid\n",
        "grid_search = GridSearchCV(nb, param_grid=param_grid, cv=5)\n",
        "grid_search.fit(train_data, train_labels)\n",
        "\n",
        "# Print the best parameter combination found\n",
        "print(\"Best parameters (Grid Search):\", grid_search.best_params_)\n",
        "\n",
        "# Perform a random search over the parameter grid\n",
        "random_search = RandomizedSearchCV(nb, param_distributions=param_grid, cv=5, n_iter=10)\n",
        "random_search.fit(train_data, train_labels)\n",
        "\n",
        "# Print the best parameter combination found\n",
        "print(\"Best parameters (Random Search):\", random_search.best_params_)\n",
        "\n",
        "# Define the Naive Bayes classifier with the best parameter combination\n",
        "best_nb = GaussianNB(var_smoothing=random_search.best_params_['var_smoothing'])\n",
        "\n",
        "# Train the Naive Bayes classifier on the training data\n",
        "best_nb.fit(train_data, train_labels)\n",
        "\n",
        "# Predict the labels of the test data\n",
        "predicted_labels = best_nb.predict(test_data)\n",
        "\n",
        "# Evaluate the performance of the Naive Bayes classifier\n",
        "accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "precision = precision_score(test_labels, predicted_labels, average='macro')\n",
        "recall = recall_score(test_labels, predicted_labels, average='macro')\n",
        "f1 = f1_score(test_labels, predicted_labels, average='macro')\n",
        "confusion_matrix = confusion_matrix(test_labels, predicted_labels)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pbeYZN9_aNDK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}